{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae821e89",
   "metadata": {},
   "source": [
    "# COSC 74 - Homework 4\n",
    "## Nikhil Pande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c784b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import statistics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff66f95",
   "metadata": {},
   "source": [
    "### Part I: Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60347f28",
   "metadata": {},
   "source": [
    "You are given a training dataset in CSV format (hw4_naive.csv). The training data has\n",
    "5,600 rows:\n",
    "- Columns 1 through 6 of the given CSV file represent the features (X)\n",
    "- The last column (“Label”) represents the class label (Y) (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893b47c",
   "metadata": {},
   "source": [
    "1) Divide the data into test / train sets (80% and 20% respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3542a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "naive = np.loadtxt(\"hw4_naive.csv\", skiprows = 1, delimiter = \",\")\n",
    "train, test = train_test_split(naive, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2d4b8",
   "metadata": {},
   "source": [
    "2) Implement a Multinomial Naïve Bayes classifier from scratch, with\n",
    "smoothing. You can set the default smoothing value to 1. You are free to code\n",
    "this up however you like, however, make sure that there is a function that can be\n",
    "called with a test X vector and returns the predicted Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e4842703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiBayes(train, x):\n",
    "    likelihood = 0\n",
    "    prior = 0\n",
    "    numrows = len(train)\n",
    "    m = []\n",
    "    n = []\n",
    "    \n",
    "    # counts start at one because of smoothing\n",
    "    m_count=[1,1,1,1,1,1]\n",
    "    n_count=[1,1,1,1,1,1]\n",
    "    \n",
    "    for row in train:\n",
    "        # Calculate prior\n",
    "        prior += row[6]\n",
    "        \n",
    "        if (row[6] == 1):\n",
    "            m.append(row)\n",
    "            for i in range(len(row)-1):\n",
    "                if row[i]==x[i]:\n",
    "                    m_count[i]+=1\n",
    "            \n",
    "        else:\n",
    "            n.append(row)\n",
    "            for i in range(len(row)-1):\n",
    "                if row[i]==x[i]:\n",
    "                    n_count[i]+=1\n",
    "        \n",
    "    prior = prior / numrows\n",
    "    \n",
    "    # likelihood for m (1)\n",
    "    likelihood_m = prior\n",
    "    for count in m_count:\n",
    "        likelihood_m += np.log(count / (len(m) + 6))  # Laplace smoothing with a count of 1\n",
    "        \n",
    "    # likelihood for n (0)\n",
    "    likelihood_n = 1 - prior\n",
    "    for count in n_count:\n",
    "        likelihood_n += np.log(count / (len(n) + 6))  # Laplace smoothing with a count of 1\n",
    "\n",
    "    \n",
    "    # compare\n",
    "    if likelihood_n > likelihood_m:\n",
    "        return 0\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37c938",
   "metadata": {},
   "source": [
    "3) Implement a Gaussian Naïve Bayes classifier from scratch (no need for smoothing here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "86922c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussBayes(train, x):\n",
    "    likelihood = 0\n",
    "    prior = 0\n",
    "    numrows = len(train)\n",
    "    m = []\n",
    "    n = []\n",
    "    \n",
    "    # initialize array of arrays, where the inner array tracks\n",
    "    # the observations for each feature where label = 1 (m) or\n",
    "    # label = 0 (n)\n",
    "    m_count = [[], [], [], [], [], []]\n",
    "    n_count= [[], [], [], [], [], []]\n",
    "    \n",
    "    \n",
    "    for row in train:\n",
    "        # Calculate prior\n",
    "        prior += row[6]\n",
    "        \n",
    "        if (row[6] == 1):\n",
    "            m.append(row)\n",
    "            for i in range(len(row)-1):\n",
    "                m_count[i].append(row[i])\n",
    "            \n",
    "        else:\n",
    "            n.append(row)\n",
    "            for i in range(len(row)-1):\n",
    "                n_count[i].append(row[i])\n",
    "\n",
    "                \n",
    "    # calculate prior\n",
    "    prior = prior / numrows\n",
    "                \n",
    "    # calculate mean and stddev for ultimate formula\n",
    "    means_m = []\n",
    "    means_n = []\n",
    "    var_m = []\n",
    "    var_n = []\n",
    "    \n",
    "    for i in range(len(m_count)):\n",
    "        means_m.append(np.mean(np.array(m_count[i])))\n",
    "        means_n.append(np.mean(np.array(n_count[i])))\n",
    "        var_m.append(np.std(n_count[i])**2)\n",
    "        var_n.append(np.std(m_count[i])**2)\n",
    "            \n",
    "    # l_m = likelihood of m (1)\n",
    "    l_m = prior\n",
    "    l_n = 1-prior\n",
    "    \n",
    "    for i in range(len(m_count)):\n",
    "        l_m = l_m*(1/np.sqrt(2*np.pi*var_m[i])) * np.exp(-1 * (x[i] - means_m[i])**2 / (2*var_m[i]))\n",
    "        l_n = l_n*(1/np.sqrt(2*np.pi*var_n[i])) * np.exp(-1 * (x[i] - means_n[i])**2 / (2*var_n[i]))\n",
    "            \n",
    "    if l_m >= l_n:\n",
    "        return 1\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cfae4c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB variables\n",
    "TPm = 0\n",
    "FPm = 0\n",
    "FNm = 0\n",
    "TNm = 0\n",
    "\n",
    "# Gaussian NB Variables\n",
    "TPg = 0\n",
    "FPg = 0\n",
    "FNg = 0\n",
    "TNg = 0\n",
    "\n",
    "\n",
    "for x in test:\n",
    "    pred_m = MultiBayes(train, x)\n",
    "    pred_g = GaussBayes(train, x)\n",
    "    \n",
    "    # calculate multinomial scores\n",
    "    if pred_m == 1 and x[6] == 1:\n",
    "        TPm += 1\n",
    "    elif pred_m == 1:\n",
    "        FPm += 1\n",
    "    elif x[6] == 1:\n",
    "        FNm += 1\n",
    "    else:\n",
    "        TNm += 1 \n",
    "        \n",
    "    # calculate gaussian scores\n",
    "    if pred_g == 1 and x[6] == 1:\n",
    "        TPg += 1\n",
    "    elif pred_g == 1:\n",
    "        FPg += 1\n",
    "    elif x[6] == 1:\n",
    "        FNg += 1\n",
    "    else:\n",
    "        TNg += 1\n",
    "        \n",
    "print(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "cc1c67d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB Accuracy:  0.8723214285714286\n",
      "Multinomial NB F1:  0.8511966701352758\n"
     ]
    }
   ],
   "source": [
    "precisionm = TPm / (TPm+FPm)\n",
    "recallm = TPm / (TPm+FNm)\n",
    "accuracym = (TPm+TNm) / (TPm+TNm+FPm+FNm)\n",
    "F1m=2*precisionm*recallm / (precisionm + recallm)\n",
    "\n",
    "\n",
    "print(\"Multinomial NB Accuracy: \", accuracym)\n",
    "print(\"Multinomial NB F1: \", F1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6e5f0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Accuracy:  0.4375\n",
      "Multinomial NB F1:  0.5007923930269415\n"
     ]
    }
   ],
   "source": [
    "precisiong = TPg / (TPg + FPg)\n",
    "recallg = TPg / (TPg + FNg)\n",
    "accuracyg = (TPg+TNg) / (TPg+TNg+FPg+FNg)\n",
    "F1g=2*precisiong*recallg / (precisiong + recallg)\n",
    "\n",
    "\n",
    "print(\"Gaussian NB Accuracy: \", accuracyg)\n",
    "print(\"Multinomial NB F1: \", F1g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ee04e",
   "metadata": {},
   "source": [
    "### Part II: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58d861",
   "metadata": {},
   "source": [
    "You are given a training dataset in CSV format (hw4_cluster.csv). The files each contain\n",
    "40 rows with 2 columns. Column 1 & 2 are the features. There are no labels for this\n",
    "dataset. Your goal for this assignment is to implement a clustering algorithm and run it\n",
    "on this dataset. For this assignment you can the Euclidean distance as the distance\n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb7f77",
   "metadata": {},
   "source": [
    "1) Implement a generalized K-means algorithm from scratch. You should have a single function that takes in as input the data points, K, and some other hyperparameters, specified below. The function should return K sets of data points. Each set corresponding to one cluster.\n",
    "\n",
    "The hyperparameters your functions should support and the values they can take are:\n",
    "- The method for calculating the centroid (i.e. the mean)\n",
    "- The initialization method: Random Split Initialization or Random Seed Selection Method\n",
    "- Max_iter: max number of iterations to run the algorithm.\n",
    "- K: number of clusters\n",
    "\n",
    "Note that your stopping condition should have two parts:\n",
    "1. Stop if you reach the max iterations\n",
    "2. Stop if no change is made to the clusters in the last step.\n",
    "\n",
    "You will be running this code as part of the next question. For this part you just need to\n",
    "implement the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0abdceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = np.loadtxt(\"hw4_cluster.csv\", delimiter = \",\", skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "726832be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHODS\n",
    "# two methods to initialize the centroids\n",
    "def random_split(data, K, centroid_method):\n",
    "    clusters = np.array_split(data, K)\n",
    "    centroids = update_centroids(clusters, centroid_method)\n",
    "    return centroids\n",
    "    \n",
    "def random_seed(data, K, centroid_method):\n",
    "    seeds = np.random.choice(len(data), K, replace = False)\n",
    "    centroids = data[seeds]\n",
    "    return centroids\n",
    "    \n",
    "\n",
    "# method to calculate distance between points and centroid, depending on method\n",
    "def distance(point, centroid, centroid_method):\n",
    "    if centroid_method == 'mean':\n",
    "        return np.linalg.norm(point - centroid, ord = 2)\n",
    "\n",
    "    elif centroid_method == 'median':\n",
    "        return np.linalg.norm(point - centroid, ord = 1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('distance method must be mean or median.')\n",
    "\n",
    "# method to update centroids based on clusters and method\n",
    "def update_centroids(clusters, centroid_method):\n",
    "    centroids = []\n",
    "\n",
    "    for cluster in clusters:\n",
    "        if centroid_method == 'mean':\n",
    "          centroid = np.mean(cluster, axis = 0)\n",
    "\n",
    "        elif centroid_method == 'median':\n",
    "          centroid = np.median(cluster, axis = 0)\n",
    "\n",
    "        else:\n",
    "          raise ValueError('centroid method must be mean or median.')\n",
    "\n",
    "        centroids.append(centroid)\n",
    "\n",
    "    return centroids\n",
    "\n",
    "# overall k_means implementation, using the above methods\n",
    "def k_means(data, K, initialization_method = random_split, centroid_method = 'mean', max_iter = 100):\n",
    "    centroids = initialization_method(data, K, centroid_method)\n",
    "\n",
    "    # loop until max iters has been reached\n",
    "    for _ in range(max_iter):\n",
    "        \n",
    "        clusters = [[] for _ in range(len(centroids))]\n",
    "\n",
    "        for point in data:\n",
    "            closest = min(range(len(centroids)), key = lambda i: distance(point, centroids[i], centroid_method))\n",
    "            clusters[closest].append(point)\n",
    "            \n",
    "        previous_centroids = centroids\n",
    "        centroids = update_centroids(clusters, centroid_method) # update the centroids\n",
    "\n",
    "        # or stop when no change has been made\n",
    "        if np.array_equal(previous_centroids, centroids):\n",
    "            break\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87726e2e",
   "metadata": {},
   "source": [
    "2) Silhouette score. In this part of the assignment, you are implementing a function from scratch that calculates the Silhouette score for a list of clusters. The function should take in a list of clusters (such as the output of the last function you implemented) and return a single Silhouette score. Report the Silhouette score for {k=5, Initialization method = Random Seed Selection, Max_iter = 50, method for calculating centroid = mean} using your K-Means code from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "780c8db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6210914928018528"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate the avg distance between two clusters\n",
    "def average_distance(cluster, other_cluster):\n",
    "  distance = 0\n",
    "\n",
    "  for i in range(len(cluster)):\n",
    "    for j in range(len(other_cluster)):\n",
    "      distance += np.linalg.norm(cluster[i] - other_cluster[j], ord = 2)\n",
    "  \n",
    "  return distance / len(other_cluster)\n",
    "\n",
    "\n",
    "def sil(clusters):\n",
    "    cluster_count = 0\n",
    "    for cluster in clusters:\n",
    "        if not np.array_equal(cluster, np.array([])):\n",
    "            cluster_count += 1\n",
    "            \n",
    "    if cluster_count <= 1:\n",
    "        return -1  # Silhouette score is -1\n",
    "\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for i, cluster in enumerate(clusters): \n",
    "        # Calculate a(i) - average distance from data point to other points in same cluster\n",
    "        a_i = average_distance(cluster, cluster)\n",
    "        \n",
    "        # Calculate b(i) - average distance from data point to points in other cluster\n",
    "        b_values = []\n",
    "        for j, other in enumerate(clusters):\n",
    "            if i != j:\n",
    "                b_values.append(average_distance(cluster, other))\n",
    "\n",
    "        b_i = min(b_values)\n",
    "        \n",
    "        \n",
    "        # Calculate Silhouette score for this cluster\n",
    "        s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "        silhouette_scores.append(s_i)\n",
    "            \n",
    "    # Overall Silhouette score is the mean of the Silhouette scores for all clusters\n",
    "    return np.mean(silhouette_scores)\n",
    "\n",
    "\n",
    "# test silhouette function\n",
    "c1 = k_means(cluster, 5, random_seed, 'mean', 50)\n",
    "\n",
    "sil(c1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c51d6",
   "metadata": {},
   "source": [
    "### Bonus Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553409b",
   "metadata": {},
   "source": [
    "Finding best K. Run the code you implemented in question 1 for\n",
    "k=2,3,4,5. Set the other hyperparameters to the following:\n",
    "- The method for calculating the centroid: Mean\n",
    "- The initialization method: Random Split Initialization\n",
    "- Max_iterations: 100\n",
    "\n",
    "Calculate the Silhouette score for each K using the function in question 2 and use these\n",
    "scores to pick the best K. What is the best value of K?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4719566b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12fce8d60>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqNElEQVR4nO3dcXDU9Z3/8dcmkF0VsklEkwAxptTDQMSRzZEmEDunaYB60YxTDPYMQqE9OKqEeF5JA0VAzIGcNaeT9NBwHBUlUyJW28AQb0gKBy0SsFWgUiReYtyYJtpdTo5Ewvf3B5f9ddkNZFMgnyTPx8x3xnz2/f3y+X7m4+xrPt/dz9osy7IEAABgsLD+7gAAAMDlEFgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYb1t8duFLOnz+vTz75RCNHjpTNZuvv7gAAgF6wLEunT5/W6NGjFRbW8zrKoAksn3zyiRISEvq7GwAAoA+ampo0duzYHl8fNIFl5MiRki7ccGRkZD/3BgAA9IbX61VCQoLvfbwngyawdD8GioyMJLAAADDAXO7jHHzoFgAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAw3qDZOO5q6Dpv6WDDZ2o9fVY3j3RoSlKMwsP4nSIAAK41AksPdr3v1qq3jsntOetri3c6tDJngmakxPdjzwAAGHp4JBTErvfdWvTKYb+wIkktnrNa9Mph7Xrf3U89AwBgaCKwXKTrvKVVbx2TFeS17rZVbx1T1/lgFQAA4GogsFzkYMNnASsrf86S5Pac1cGGz65dpwAAGOIILBdpPd1zWOlLHQAA+MsRWC5y80jHFa0DAAB/OQLLRaYkxSje6VBPX1626cK3haYkxVzLbgEAMKQRWC4SHmbTypwJkhQQWrr/Xpkzgf1YAAC4hggsQcxIiVf5I5MV5/R/7BPndKj8kcnswwIAwDXGxnE9mJESr29MiGOnWwAADEBguYTwMJvSx93Y390AAGDI45EQAAAwXp8CS1lZmZKSkuRwOORyubR3795L1m/dulV33nmnrr/+esXHx2vevHlqb2/3vf7SSy8pMzNT0dHRio6OVlZWlg4ePNiXrgEAgEEo5MBSWVmpgoICFRcX68iRI8rMzNTMmTPV2NgYtH7fvn2aM2eO5s+fr6NHj+pnP/uZ3nnnHS1YsMBXU1tbq4cfflh79uzRgQMHdMsttyg7O1vNzc19vzMAADBo2CzLCulHcdLS0jR58mSVl5f72pKTk5Wbm6uSkpKA+g0bNqi8vFwffvihr+2FF17Q+vXr1dTUFPTf6OrqUnR0tF588UXNmTOnV/3yer1yOp3yeDyKjIwM5ZYAAEA/6e37d0grLJ2dnaqvr1d2drZfe3Z2tvbv3x/0nIyMDH388ceqrq6WZVn69NNPtX37dt133309/jtnzpzRl19+qZiYnjdn6+jokNfr9TsAAMDgFFJgaWtrU1dXl2JjY/3aY2Nj1dLSEvScjIwMbd26VXl5eYqIiFBcXJyioqL0wgsv9PjvLFu2TGPGjFFWVlaPNSUlJXI6nb4jISEhlFsBAAADSJ8+dGuz+e9FYllWQFu3Y8eO6fHHH9ePfvQj1dfXa9euXWpoaNDChQuD1q9fv16vvfaaXn/9dTkcPf9eT1FRkTwej+/o6fESAAAY+ELah2XUqFEKDw8PWE1pbW0NWHXpVlJSoqlTp+rJJ5+UJE2aNEk33HCDMjMz9fTTTys+/v/vGrthwwY988wzevvttzVp0qRL9sVut8tut4fSfQAAMECFtMISEREhl8ulmpoav/aamhplZGQEPefMmTMKC/P/Z8LDwyVdWJnp9uyzz2rNmjXatWuXUlNTQ+kWAAAY5ELe6bawsFD5+flKTU1Venq6Nm7cqMbGRt8jnqKiIjU3N2vLli2SpJycHH33u99VeXm5pk+fLrfbrYKCAk2ZMkWjR4+WdOEx0IoVK/Tqq6/q1ltv9a3gjBgxQiNGjLhS9woAAAaokANLXl6e2tvbtXr1arndbqWkpKi6ulqJiYmSJLfb7bcny9y5c3X69Gm9+OKLeuKJJxQVFaV77rlH69at89WUlZWps7NT3/rWt/z+rZUrV+qpp57q460BAIDBIuR9WEzFPiwAAAw8V2UfFgAAgP5AYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4/UpsJSVlSkpKUkOh0Mul0t79+69ZP3WrVt155136vrrr1d8fLzmzZun9vZ2v5qqqipNmDBBdrtdEyZM0I4dO/rSNQAAMAiFHFgqKytVUFCg4uJiHTlyRJmZmZo5c6YaGxuD1u/bt09z5szR/PnzdfToUf3sZz/TO++8owULFvhqDhw4oLy8POXn5+u3v/2t8vPz9dBDD+k3v/lN3+8MAAAMGjbLsqxQTkhLS9PkyZNVXl7ua0tOTlZubq5KSkoC6jds2KDy8nJ9+OGHvrYXXnhB69evV1NTkyQpLy9PXq9XO3fu9NXMmDFD0dHReu2113rVL6/XK6fTKY/Ho8jIyFBuCQAA9JPevn+HtMLS2dmp+vp6ZWdn+7VnZ2dr//79Qc/JyMjQxx9/rOrqalmWpU8//VTbt2/Xfffd56s5cOBAwDWnT5/e4zUlqaOjQ16v1+8AAACDU0iBpa2tTV1dXYqNjfVrj42NVUtLS9BzMjIytHXrVuXl5SkiIkJxcXGKiorSCy+84KtpaWkJ6ZqSVFJSIqfT6TsSEhJCuRUAADCA9OlDtzabze9vy7IC2rodO3ZMjz/+uH70ox+pvr5eu3btUkNDgxYuXNjna0pSUVGRPB6P7+h+vAQAAAafYaEUjxo1SuHh4QErH62trQErJN1KSko0depUPfnkk5KkSZMm6YYbblBmZqaefvppxcfHKy4uLqRrSpLdbpfdbg+l+wAAYIAKaYUlIiJCLpdLNTU1fu01NTXKyMgIes6ZM2cUFub/z4SHh0u6sIoiSenp6QHX3L17d4/XBAAAQ0tIKyySVFhYqPz8fKWmpio9PV0bN25UY2Oj7xFPUVGRmpubtWXLFklSTk6Ovvvd76q8vFzTp0+X2+1WQUGBpkyZotGjR0uSlixZorvvvlvr1q3TAw88oJ///Od6++23tW/fvit4qwAAYKAKObDk5eWpvb1dq1evltvtVkpKiqqrq5WYmChJcrvdfnuyzJ07V6dPn9aLL76oJ554QlFRUbrnnnu0bt06X01GRoa2bdum5cuXa8WKFRo3bpwqKyuVlpZ2BW4RAAAMdCHvw2Iq9mEBAGDguSr7sAAAAPQHAgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYLxh/d0BYCjqOm/pYMNnaj19VjePdGhKUozCw2z93S0AMBaBBbjGdr3v1qq3jsntOetri3c6tDJngmakxPdjzwDAXH16JFRWVqakpCQ5HA65XC7t3bu3x9q5c+fKZrMFHBMnTvSre/755zV+/Hhdd911SkhI0NKlS3X27NkergoMTLved2vRK4f9wooktXjOatErh7XrfXc/9QwAzBZyYKmsrFRBQYGKi4t15MgRZWZmaubMmWpsbAxaX1paKrfb7TuampoUExOjWbNm+Wq2bt2qZcuWaeXKlTp+/LgqKipUWVmpoqKivt8ZYJiu85ZWvXVMVpDXuttWvXVMXeeDVQDA0BZyYHnuuec0f/58LViwQMnJyXr++eeVkJCg8vLyoPVOp1NxcXG+49ChQ/r88881b948X82BAwc0depUffvb39att96q7OxsPfzwwzp06FDf7wwwzMGGzwJWVv6cJcntOauDDZ9du04BwAARUmDp7OxUfX29srOz/dqzs7O1f//+Xl2joqJCWVlZSkxM9LVNmzZN9fX1OnjwoCTp1KlTqq6u1n333dfjdTo6OuT1ev0OwGStp3v3iLO3dQAwlIT0odu2tjZ1dXUpNjbWrz02NlYtLS2XPd/tdmvnzp169dVX/dpnz56tP/7xj5o2bZosy9K5c+e0aNEiLVu2rMdrlZSUaNWqVaF0H+hXN490XNE6ABhK+vShW5vN/+uXlmUFtAWzefNmRUVFKTc316+9trZWa9euVVlZmQ4fPqzXX39dv/jFL7RmzZoer1VUVCSPx+M7mpqa+nIrwDUzJSlG8U6Hevo/xaYL3xaakhRzLbsFAANCSCsso0aNUnh4eMBqSmtra8Cqy8Usy9KmTZuUn5+viIgIv9dWrFih/Px8LViwQJJ0xx136IsvvtD3vvc9FRcXKywsMFfZ7XbZ7fZQug/0q/Awm1bmTNCiVw7LJvl9+LY7xKzMmcB+LAAQREgrLBEREXK5XKqpqfFrr6mpUUZGxiXPraur08mTJzV//vyA186cORMQSsLDw2VZliyLb0xg8JiREq/yRyYrzun/2CfO6VD5I5PZhwUAehDyxnGFhYXKz89Xamqq0tPTtXHjRjU2NmrhwoWSLjyqaW5u1pYtW/zOq6ioUFpamlJSUgKumZOTo+eee0533XWX0tLSdPLkSa1YsUL333+/wsPD+3hrgJlmpMTrGxPi2OkWAEIQcmDJy8tTe3u7Vq9eLbfbrZSUFFVXV/u+9eN2uwP2ZPF4PKqqqlJpaWnQay5fvlw2m03Lly9Xc3OzbrrpJuXk5Gjt2rV9uCXAfOFhNqWPu7G/uwEAA4bNGiTPXLxer5xOpzwejyIjI/u7OwAAoBd6+/7NrzUDAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHh9CixlZWVKSkqSw+GQy+XS3r17e6ydO3eubDZbwDFx4kS/uj/96U9avHix4uPj5XA4lJycrOrq6r50DwAADDIhB5bKykoVFBSouLhYR44cUWZmpmbOnKnGxsag9aWlpXK73b6jqalJMTExmjVrlq+ms7NT3/jGN/TRRx9p+/bt+uCDD/TSSy9pzJgxfb8zAAAwaNgsy7JCOSEtLU2TJ09WeXm5ry05OVm5ubkqKSm57PlvvPGGHnzwQTU0NCgxMVGS9JOf/ETPPvusfv/732v48OEh3sIFXq9XTqdTHo9HkZGRfboGAAC4tnr7/h3SCktnZ6fq6+uVnZ3t156dna39+/f36hoVFRXKysryhRVJevPNN5Wenq7FixcrNjZWKSkpeuaZZ9TV1dXjdTo6OuT1ev0OAAAwOIUUWNra2tTV1aXY2Fi/9tjYWLW0tFz2fLfbrZ07d2rBggV+7adOndL27dvV1dWl6upqLV++XP/yL/+itWvX9nitkpISOZ1O35GQkBDKrQAAgAGkTx+6tdlsfn9blhXQFszmzZsVFRWl3Nxcv/bz58/r5ptv1saNG+VyuTR79mwVFxf7PXa6WFFRkTwej+9oamrqy60AAIABYFgoxaNGjVJ4eHjAakpra2vAqsvFLMvSpk2blJ+fr4iICL/X4uPjNXz4cIWHh/vakpOT1dLSos7OzoB6SbLb7bLb7aF0HwAADFAhrbBERETI5XKppqbGr72mpkYZGRmXPLeurk4nT57U/PnzA16bOnWqTp48qfPnz/vaTpw4ofj4+KBhBQAADC0hPxIqLCzUyy+/rE2bNun48eNaunSpGhsbtXDhQkkXHtXMmTMn4LyKigqlpaUpJSUl4LVFixapvb1dS5Ys0YkTJ/TLX/5SzzzzjBYvXtyHWwIAAINNSI+EJCkvL0/t7e1avXq13G63UlJSVF1d7fvWj9vtDtiTxePxqKqqSqWlpUGvmZCQoN27d2vp0qWaNGmSxowZoyVLlugHP/hBH24JAAAMNiHvw2Iq9mEBAGDguSr7sAAAAPQHAgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMF6fAktZWZmSkpLkcDjkcrm0d+/eHmvnzp0rm80WcEycODFo/bZt22Sz2ZSbm9uXrgEAgEEo5MBSWVmpgoICFRcX68iRI8rMzNTMmTPV2NgYtL60tFRut9t3NDU1KSYmRrNmzQqo/e///m/94z/+ozIzM0O/EwAAMGiFHFiee+45zZ8/XwsWLFBycrKef/55JSQkqLy8PGi90+lUXFyc7zh06JA+//xzzZs3z6+uq6tLf/d3f6dVq1bpK1/5St/uBgAADEohBZbOzk7V19crOzvbrz07O1v79+/v1TUqKiqUlZWlxMREv/bVq1frpptu0vz583t1nY6ODnm9Xr8DAAAMTsNCKW5ra1NXV5diY2P92mNjY9XS0nLZ891ut3bu3KlXX33Vr/2//uu/VFFRoXfffbfXfSkpKdGqVat6XQ8AAAauPn3o1maz+f1tWVZAWzCbN29WVFSU3wdqT58+rUceeUQvvfSSRo0a1es+FBUVyePx+I6mpqZenwsAAAaWkFZYRo0apfDw8IDVlNbW1oBVl4tZlqVNmzYpPz9fERERvvYPP/xQH330kXJycnxt58+fv9C5YcP0wQcfaNy4cQHXs9vtstvtoXQfAAAMUCGtsERERMjlcqmmpsavvaamRhkZGZc8t66uTidPngz4jMrtt9+u9957T++++67vuP/++/U3f/M3evfdd5WQkBBKFwEAwCAU0gqLJBUWFio/P1+pqalKT0/Xxo0b1djYqIULF0q68KimublZW7Zs8TuvoqJCaWlpSklJ8Wt3OBwBbVFRUZIU0A4AAIamkANLXl6e2tvbtXr1arndbqWkpKi6utr3rR+32x2wJ4vH41FVVZVKS0uvTK8BAMCQYrMsy+rvTlwJXq9XTqdTHo9HkZGR/d0dAADQC719/+a3hAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgvD4FlrKyMiUlJcnhcMjlcmnv3r091s6dO1c2my3gmDhxoq/mpZdeUmZmpqKjoxUdHa2srCwdPHiwL10DAACDUMiBpbKyUgUFBSouLtaRI0eUmZmpmTNnqrGxMWh9aWmp3G6372hqalJMTIxmzZrlq6mtrdXDDz+sPXv26MCBA7rllluUnZ2t5ubmvt8ZAAAYNGyWZVmhnJCWlqbJkyervLzc15acnKzc3FyVlJRc9vw33nhDDz74oBoaGpSYmBi0pqurS9HR0XrxxRc1Z86cXvXL6/XK6XTK4/EoMjKydzcDAAD6VW/fv0NaYens7FR9fb2ys7P92rOzs7V///5eXaOiokJZWVk9hhVJOnPmjL788kvFxMT0WNPR0SGv1+t3AACAwSmkwNLW1qauri7Fxsb6tcfGxqqlpeWy57vdbu3cuVMLFiy4ZN2yZcs0ZswYZWVl9VhTUlIip9PpOxISEnp3EwAAYMDp04dubTab39+WZQW0BbN582ZFRUUpNze3x5r169frtdde0+uvvy6Hw9FjXVFRkTwej+9oamrqdf8BAMDAMiyU4lGjRik8PDxgNaW1tTVg1eVilmVp06ZNys/PV0RERNCaDRs26JlnntHbb7+tSZMmXfJ6drtddrs9lO4DAIABKqQVloiICLlcLtXU1Pi119TUKCMj45Ln1tXV6eTJk5o/f37Q15999lmtWbNGu3btUmpqaijdAgAAg1xIKyySVFhYqPz8fKWmpio9PV0bN25UY2OjFi5cKOnCo5rm5mZt2bLF77yKigqlpaUpJSUl4Jrr16/XihUr9Oqrr+rWW2/1reCMGDFCI0aM6Mt9AQCAQSTkwJKXl6f29natXr1abrdbKSkpqq6u9n3rx+12B+zJ4vF4VFVVpdLS0qDXLCsrU2dnp771rW/5ta9cuVJPPfVUqF0EAACDTMj7sJiKfVgAABh4rso+LAAAAP2BwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxutTYCkrK1NSUpIcDodcLpf27t3bY+3cuXNls9kCjokTJ/rVVVVVacKECbLb7ZowYYJ27NjRl64BAIBBKOTAUllZqYKCAhUXF+vIkSPKzMzUzJkz1djYGLS+tLRUbrfbdzQ1NSkmJkazZs3y1Rw4cEB5eXnKz8/Xb3/7W+Xn5+uhhx7Sb37zm77fGQAAGDRslmVZoZyQlpamyZMnq7y83NeWnJys3NxclZSUXPb8N954Qw8++KAaGhqUmJgoScrLy5PX69XOnTt9dTNmzFB0dLRee+21XvXL6/XK6XTK4/EoMjIylFsCAAD9pLfv3yGtsHR2dqq+vl7Z2dl+7dnZ2dq/f3+vrlFRUaGsrCxfWJEurLBcfM3p06df8podHR3yer1+BwAAGJxCCixtbW3q6upSbGysX3tsbKxaWloue77b7dbOnTu1YMECv/aWlpaQr1lSUiKn0+k7EhISQrgTAAAwkPTpQ7c2m83vb8uyAtqC2bx5s6KiopSbm/sXX7OoqEgej8d3NDU19a7zAABgwBkWSvGoUaMUHh4esPLR2toasEJyMcuytGnTJuXn5ysiIsLvtbi4uJCvabfbZbfbQ+k+AAAYoEJaYYmIiJDL5VJNTY1fe01NjTIyMi55bl1dnU6ePKn58+cHvJaenh5wzd27d1/2mgAAYGgIaYVFkgoLC5Wfn6/U1FSlp6dr48aNamxs1MKFCyVdeFTT3NysLVu2+J1XUVGhtLQ0paSkBFxzyZIluvvuu7Vu3To98MAD+vnPf663335b+/bt6+NtAQCAwSTkwJKXl6f29natXr1abrdbKSkpqq6u9n3rx+12B+zJ4vF4VFVVpdLS0qDXzMjI0LZt27R8+XKtWLFC48aNU2VlpdLS0vpwSwAAYLAJeR8WU7EPCwAAA89V2YcFAACgPxBYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeMP6uwMAgCuj67ylgw2fqfX0Wd080qEpSTEKD7P1d7eAK4LAAgCDwK733Vr11jG5PWd9bfFOh1bmTNCMlPh+7BlwZfBICAAGuF3vu7XolcN+YUWSWjxnteiVw9r1vrufegZcOQQWABjAus5bWvXWMVlBXutuW/XWMXWdD1YBDBwEFgAYwA42fBawsvLnLEluz1kdbPjs2nUKuAoILAAwgLWe7jms9KUOMBWBBQAGsJtHOq5oHWAqAgsADGBTkmIU73Sopy8v23Th20JTkmKuZbeAK65PgaWsrExJSUlyOBxyuVzau3fvJes7OjpUXFysxMRE2e12jRs3Tps2bfKref755zV+/Hhdd911SkhI0NKlS3X2LEuYAHAp4WE2rcyZIEkBoaX775U5E9iPBQNeyPuwVFZWqqCgQGVlZZo6dar+7d/+TTNnztSxY8d0yy23BD3noYce0qeffqqKigp99atfVWtrq86dO+d7fevWrVq2bJk2bdqkjIwMnThxQnPnzpUk/fjHP+7bnQHAEDEjJV7lj0wO2Icljn1YMIjYLMsK6btuaWlpmjx5ssrLy31tycnJys3NVUlJSUD9rl27NHv2bJ06dUoxMcGXJL///e/r+PHj+s///E9f2xNPPKGDBw9edvWmm9frldPplMfjUWRkZCi3BACDAjvd4mq42vOqt+/fIa2wdHZ2qr6+XsuWLfNrz87O1v79+4Oe8+abbyo1NVXr16/XT3/6U91www26//77tWbNGl133XWSpGnTpumVV17RwYMHNWXKFJ06dUrV1dV69NFHe+xLR0eHOjo6/G4YAIay8DCb0sfd2N/dwCBi0g7KIQWWtrY2dXV1KTY21q89NjZWLS0tQc85deqU9u3bJ4fDoR07dqitrU3/8A//oM8++8z3OZbZs2frj3/8o6ZNmybLsnTu3DktWrQoIBj9uZKSEq1atSqU7gMAgF7q3kH54scw3Tsolz8y+ZqGlj596NZm818KsiwroK3b+fPnZbPZtHXrVk2ZMkXf/OY39dxzz2nz5s363//9X0lSbW2t1q5dq7KyMh0+fFivv/66fvGLX2jNmjU99qGoqEgej8d3NDU19eVWAADARUzcQTmkFZZRo0YpPDw8YDWltbU1YNWlW3x8vMaMGSOn0+lrS05OlmVZ+vjjj3XbbbdpxYoVys/P14IFCyRJd9xxh7744gt973vfU3FxscLCAnOV3W6X3W4PpfsAAKAXQtlB+Vo9hgxphSUiIkIul0s1NTV+7TU1NcrIyAh6ztSpU/XJJ5/of/7nf3xtJ06cUFhYmMaOHStJOnPmTEAoCQ8Pl2VZCvEzwQAA4C9k4g7KIT8SKiws1Msvv6xNmzbp+PHjWrp0qRobG7Vw4UJJFx7VzJkzx1f/7W9/WzfeeKPmzZunY8eO6Ve/+pWefPJJfec73/F96DYnJ0fl5eXatm2bGhoaVFNToxUrVuj+++9XeHj4FbpVAADQGybuoBzyPix5eXlqb2/X6tWr5Xa7lZKSourqaiUmJkqS3G63GhsbffUjRoxQTU2NHnvsMaWmpurGG2/UQw89pKefftpXs3z5ctlsNi1fvlzNzc266aablJOTo7Vr116BWwQAAKHo3kG5xXM26OdYbLqwz8+13EE55H1YTMU+LAAAXDnd3xKS5Bdaur9ic6W+JdTb929+SwgAAATo3kE5zun/2CfO6bjmX2mW+vBICAAADA0zUuL1jQlxRuygTGABAAA9MmUHZR4JAQAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjDZqdbrt/w9Hr9fZzTwAAQG91v29f7reYB01gOX36tCQpISGhn3sCAABCdfr0aTmdzh5ft1mXizQDxPnz5/XJJ59o5MiRstmu3I8yeb1eJSQkqKmp6ZI/ew3GKlSMV+8xVr3HWPUeY9V7V3OsLMvS6dOnNXr0aIWF9fxJlUGzwhIWFqaxY8detetHRkYyoXuJsQoN49V7jFXvMVa9x1j13tUaq0utrHTjQ7cAAMB4BBYAAGA8Astl2O12rVy5Una7vb+7YjzGKjSMV+8xVr3HWPUeY9V7JozVoPnQLQAAGLxYYQEAAMYjsAAAAOMRWAAAgPEILAAAwHhDOrCUlJTor//6rzVy5EjdfPPNys3N1QcffHDZ8+rq6uRyueRwOPSVr3xFP/nJT65Bb/tXX8aqtrZWNpst4Pj9739/jXrdf8rLyzVp0iTfJkvp6enauXPnJc8ZivNKCn2shvK8+nMlJSWy2WwqKCi4ZN1QnVcX6814DdW59dRTTwXcc1xc3CXP6Y95NaQDS11dnRYvXqxf//rXqqmp0blz55Sdna0vvviix3MaGhr0zW9+U5mZmTpy5Ih++MMf6vHHH1dVVdU17Pm115ex6vbBBx/I7Xb7jttuu+0a9Lh/jR07Vv/8z/+sQ4cO6dChQ7rnnnv0wAMP6OjRo0Hrh+q8kkIfq25DcV51e+edd7Rx40ZNmjTpknVDeV79ud6OV7ehOLcmTpzod8/vvfdej7X9Nq8s+LS2tlqSrLq6uh5r/umf/sm6/fbb/dr+/u//3vra1752tbtnlN6M1Z49eyxJ1ueff37tOmaw6Oho6+WXXw76GvPK36XGaqjPq9OnT1u33XabVVNTY33961+3lixZ0mMt8yq08Rqqc2vlypXWnXfe2ev6/ppXQ3qF5WIej0eSFBMT02PNgQMHlJ2d7dc2ffp0HTp0SF9++eVV7Z9JejNW3e666y7Fx8fr3nvv1Z49e65214zT1dWlbdu26YsvvlB6enrQGubVBb0Zq25DdV4tXrxY9913n7Kysi5by7wKbby6DcW59Yc//EGjR49WUlKSZs+erVOnTvVY21/zatD8+OFfyrIsFRYWatq0aUpJSemxrqWlRbGxsX5tsbGxOnfunNra2hQfH3+1u9rvejtW8fHx2rhxo1wulzo6OvTTn/5U9957r2pra3X33Xdfwx73j/fee0/p6ek6e/asRowYoR07dmjChAlBa4f6vAplrIbyvNq2bZsOHz6sd955p1f1Q31ehTpeQ3VupaWlacuWLfqrv/orffrpp3r66aeVkZGho0eP6sYbbwyo7695RWD5P9///vf1u9/9Tvv27btsrc1m8/vb+r/Ngi9uH6x6O1bjx4/X+PHjfX+np6erqalJGzZsGNT/83cbP3683n33Xf3pT39SVVWVHn30UdXV1fX4RjyU51UoYzVU51VTU5OWLFmi3bt3y+Fw9Pq8oTqv+jJeQ3VuzZw50/ffd9xxh9LT0zVu3Dj9x3/8hwoLC4Oe0x/zikdCkh577DG9+eab2rNnj8aOHXvJ2ri4OLW0tPi1tba2atiwYUGT6GATylgF87WvfU1/+MMfrkLPzBMREaGvfvWrSk1NVUlJie68806VlpYGrR3q8yqUsQpmKMyr+vp6tba2yuVyadiwYRo2bJjq6ur0r//6rxo2bJi6uroCzhnK86ov4xXMUJhbF7vhhht0xx139Hjf/TWvhvQKi2VZeuyxx7Rjxw7V1tYqKSnpsuekp6frrbfe8mvbvXu3UlNTNXz48KvV1X7Xl7EK5siRI4N+GbonlmWpo6Mj6GtDdV715FJjFcxQmFf33ntvwDc35s2bp9tvv10/+MEPFB4eHnDOUJ5XfRmvYIbC3LpYR0eHjh8/rszMzKCv99u8uqof6TXcokWLLKfTadXW1lput9t3nDlzxlezbNkyKz8/3/f3qVOnrOuvv95aunSpdezYMauiosIaPny4tX379v64hWumL2P14x//2NqxY4d14sQJ6/3337eWLVtmSbKqqqr64xauqaKiIutXv/qV1dDQYP3ud7+zfvjDH1phYWHW7t27LctiXv25UMdqKM+ri138rRfm1aVdbryG6tx64oknrNraWuvUqVPWr3/9a+tv//ZvrZEjR1offfSRZVnmzKshHVgkBT3+/d//3Vfz6KOPWl//+tf9zqutrbXuuusuKyIiwrr11lut8vLya9vxftCXsVq3bp01btw4y+FwWNHR0da0adOsX/7yl9e+8/3gO9/5jpWYmGhFRERYN910k3Xvvff63oAti3n150Idq6E8ry528Rsw8+rSLjdeQ3Vu5eXlWfHx8dbw4cOt0aNHWw8++KB19OhR3+umzCubZf3fJ2UAAAAMxYduAQCA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADDe/wM5HwPfqag8EQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BONUS POINTS\n",
    "c2 = k_means(cluster, 2, random_split, 'mean', 100)\n",
    "c3 = k_means(cluster, 3, random_split, 'mean',  100)\n",
    "c4 = k_means(cluster, 4, random_split, 'mean', 100)\n",
    "c5 = k_means(cluster, 5, random_split, 'mean',  100)\n",
    "\n",
    "s2 = sil(c2)\n",
    "s3 = sil(c3)\n",
    "s4 = sil(c4)\n",
    "s5 = sil(c5)\n",
    "\n",
    "plt.scatter(range(2,6),[s2,s3,s4,s5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255aac9",
   "metadata": {},
   "source": [
    "**Answer:** It's clear from the scatter plot that 2 clusters is the optimal number of clusters. With this number of clusters, we have the highest silhouette score, which implies that the distance within clusters is small for two clusters, and the distance between these two clusters is large."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
