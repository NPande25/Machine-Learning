{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d695e55",
   "metadata": {},
   "source": [
    "# COSC 74 Final Project - Amazon Review Multiclass Classification\n",
    "## Nikhil Pande and Colton Sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "1f8a47d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from vaderSentiment) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: nltk in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/nikhilpande/miniconda3/lib/python3.10/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "1175dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, LabelEncoder, StandardScaler\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import re # for regex\n",
    "\n",
    "# NLTK packages\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "d48c724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.DataFrame(pd.read_csv('amazon_train.csv'))\n",
    "test_data = pd.DataFrame(pd.read_csv('amazon_test.csv'))\n",
    "\n",
    "y_train = train_data['overall']\n",
    "train_data = train_data[['reviewText', 'summary', 'verified', 'vote', 'image', 'unixReviewTime']]\n",
    "test_id = test_data['id'] # for the final submission\n",
    "test_data = test_data[['reviewText', 'summary', 'verified', 'vote', 'image', 'unixReviewTime']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5485624",
   "metadata": {},
   "source": [
    "### Preprocess and Combine Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "e4dabf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all of the reviews for this product are fake.</td>\n",
       "      <td>All fake reviews, beware.</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1478908800</td>\n",
       "      <td>all of the reviews for this product are fake. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wrong part. our fault.</td>\n",
       "      <td>One Star</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1480982400</td>\n",
       "      <td>wrong part. our fault. One Star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this wire set it really sucks!!!</td>\n",
       "      <td>One Star</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1410912000</td>\n",
       "      <td>this wire set it really sucks!!! One Star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first use, it leaked instantly. even at 5 buck...</td>\n",
       "      <td>One Star</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465603200</td>\n",
       "      <td>first use, it leaked instantly. even at 5 buck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>didn't fit</td>\n",
       "      <td>One Star</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513987200</td>\n",
       "      <td>didn't fit One Star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0      all of the reviews for this product are fake.   \n",
       "1                             wrong part. our fault.   \n",
       "2                   this wire set it really sucks!!!   \n",
       "3  first use, it leaked instantly. even at 5 buck...   \n",
       "4                                         didn't fit   \n",
       "\n",
       "                     summary  verified  vote  image  unixReviewTime  \\\n",
       "0  All fake reviews, beware.     False   2.0      0      1478908800   \n",
       "1                   One Star      True   0.0      0      1480982400   \n",
       "2                   One Star      True   0.0      0      1410912000   \n",
       "3                   One Star      True   0.0      0      1465603200   \n",
       "4                   One Star      True   0.0      0      1513987200   \n",
       "\n",
       "                                       combined_text  \n",
       "0  all of the reviews for this product are fake. ...  \n",
       "1                    wrong part. our fault. One Star  \n",
       "2          this wire set it really sucks!!! One Star  \n",
       "3  first use, it leaked instantly. even at 5 buck...  \n",
       "4                                didn't fit One Star  "
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Handle the missing values in the summary and vote columns\n",
    "train_data['summary'] = train_data['summary'].fillna(\"\") # a few na summary rows were messing with the combined text column\n",
    "test_data['summary'] = test_data['summary'].fillna(\"\")\n",
    "train_data['vote'] = train_data['vote'].fillna(0.0)\n",
    "test_data['vote'] = test_data['vote'].fillna(0.0)\n",
    "\n",
    "# put 0 (no) or 1 (yes) for whether or not there is an image\n",
    "train_data['image'] = train_data['image'].notna().astype(int)\n",
    "test_data['image'] = test_data['image'].notna().astype(int)\n",
    "\n",
    "\n",
    "# Create 'combined_text'\n",
    "train_data['combined_text'] = train_data['reviewText'] + ' ' + train_data['summary']\n",
    "test_data['combined_text'] = test_data['reviewText'] + ' ' + test_data['summary']\n",
    "\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Replace whitespace with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    # Replace \":)\" with \"happy\" in 'reviewText' and 'summary' columns\n",
    "    text.replace(\":)\", \"happy\")\n",
    "    return cleaned_text\n",
    "\n",
    "train_data['reviewText'] = train_data['reviewText'].apply(clean_text)\n",
    "test_data['reviewText'] = test_data['reviewText'].apply(clean_text)\n",
    "\n",
    "train_data['summary'] = train_data['summary'].apply(clean_text)\n",
    "test_data['summary'] = test_data['summary'].apply(clean_text)\n",
    "\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "3eace9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping between written-out numbers and numeric values\n",
    "written_numbers_mapping = {\n",
    "    'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
    "    'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10\n",
    "}\n",
    "\n",
    "# Function to convert written-out numbers to numeric\n",
    "def convert_written_number(word):\n",
    "    if pd.isna(word):\n",
    "        return word\n",
    "    return written_numbers_mapping.get(word.lower(), word)\n",
    "\n",
    "train_data['explicit_star_count'] = train_data['summary'].str.extract(r'(\\w+)\\s*star[s]*', flags=re.IGNORECASE)\n",
    "test_data['explicit_star_count'] = test_data['summary'].str.extract(r'(\\w+)\\s*star[s]*', flags=re.IGNORECASE)\n",
    "\n",
    "train_data['explicit_star_count'] = train_data['explicit_star_count'].apply(convert_written_number)\n",
    "test_data['explicit_star_count'] = test_data['explicit_star_count'].apply(convert_written_number)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "c706ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'ok' or 'okay' is present in the 'summary' column\n",
    "train_data['contains_okay'] = train_data['summary'].str.contains(r'\\bok(?:ay)?\\b', case=False)\n",
    "test_data['contains_okay'] = test_data['summary'].str.contains(r'\\bok(?:ay)?\\b', case=False)\n",
    "\n",
    "# Set 'expected_star_count' to 3 if 'contains_okay' is True, otherwise keep the existing value\n",
    "train_data['explicit_star_count'] = np.where(train_data['contains_okay'], 3, train_data['explicit_star_count'])\n",
    "test_data['explicit_star_count'] = np.where(test_data['contains_okay'], 3, test_data['explicit_star_count'])\n",
    "\n",
    "# Drop the temporary column 'contains_okay' if you don't need it\n",
    "train_data = train_data.drop('contains_okay', axis=1)\n",
    "test_data = test_data.drop('contains_okay', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "eb058563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK-based feature engineering\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Count of tokens\n",
    "# Tokenize, remove stopwords, and perform stemming\n",
    "train_data['tokens'] = train_data['combined_text'].apply(lambda x: [ps.stem(word) for word in word_tokenize(x)])\n",
    "test_data['tokens'] = test_data['combined_text'].apply(lambda x: [ps.stem(word) for word in word_tokenize(x)])\n",
    "# token_count is the length of the review\n",
    "train_data['token_count'] = train_data['tokens'].apply(len)\n",
    "test_data['token_count'] = test_data['tokens'].apply(len)\n",
    "\n",
    "# drop tokens so only word count remains\n",
    "train_data = train_data.drop('tokens', axis = 1)\n",
    "test_data = test_data.drop('tokens', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2326017d",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "d691d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment analysis\n",
    "def sentiment_analysis(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    return sentiment_score['compound'], sentiment_score['neg'], sentiment_score['pos']\n",
    "#     return sentiment_score\n",
    "\n",
    "\n",
    "# 2\n",
    "# Temporary DataFrames for 'reviewText'\n",
    "sentiment_features_train_r = train_data['combined_text'].apply(sentiment_analysis).apply(lambda x: pd.Series(x, index=['compound_r', 'neg_r', 'pos_r']))\n",
    "sentiment_features_test_r = test_data['combined_text'].apply(sentiment_analysis).apply(lambda x: pd.Series(x, index=['compound_r', 'neg_r', 'pos_r']))\n",
    "\n",
    "# Concatenate the new DataFrames with the original DataFrames\n",
    "train_data = pd.concat([train_data, sentiment_features_train_r], axis=1)\n",
    "test_data = pd.concat([test_data, sentiment_features_test_r], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae149f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data['reviewText'].str.contains(r'\\bstar[s]?\\b', case=False)].to_csv(\"stars.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f889f54",
   "metadata": {},
   "source": [
    "### NLTK: Count tokens and exclamation points (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "4aecdc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count exclamation marks!\n",
    "\n",
    "train_data['num_exclamation_marks'] = train_data['combined_text'].str.count('!')\n",
    "test_data['num_exclamation_marks'] = test_data['combined_text'].str.count('!')\n",
    "\n",
    "train_data['trust'] = train_data['compound_r'] * (train_data['vote'] ** 2)\n",
    "test_data['trust'] = test_data['compound_r'] * (test_data['vote'] ** 2)\n",
    "\n",
    "train_data['emphasis'] = train_data['num_exclamation_marks'] * train_data['compound_r']\n",
    "test_data['emphasis'] = test_data['num_exclamation_marks'] * test_data['compound_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e937680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "522fa317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for 'verified' column\n",
    "\n",
    "#LABEL ENCODER\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['verified'] = label_encoder.fit_transform(train_data['verified'])\n",
    "test_data['verified'] = label_encoder.transform(test_data['verified'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "2ccd498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = train_data.drop('combined_text', axis = 1)\n",
    "test_data = test_data.drop('combined_text', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3de62",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "76c80a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, y_train, test_size = 0.2, random_state = 0)\n",
    "y_train_actual = pd.DataFrame(pd.read_csv(\"amazon_train.csv\"))['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "d517aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'explicit_star_count' column to numeric\n",
    "X_train['explicit_star_count'] = pd.to_numeric(X_train['explicit_star_count'], errors='coerce')\n",
    "X_valid['explicit_star_count'] = pd.to_numeric(X_valid['explicit_star_count'], errors='coerce')\n",
    "test_data['explicit_star_count'] = pd.to_numeric(test_data['explicit_star_count'], errors='coerce')\n",
    "\n",
    "\n",
    "train_data['explicit_star_count'] = pd.to_numeric(train_data['explicit_star_count'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d306c",
   "metadata": {},
   "source": [
    "### Preprocess with TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "52884e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ColumnTransformer for preprocessing with tfidf\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('text', TfidfVectorizer(max_features = 3000), 'reviewText'),\n",
    "                 ('text2', TfidfVectorizer(max_features = 3000), 'summary')],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply the preprocessing to the training and test sets\n",
    "X_train_pre = preprocessor.fit_transform(X_train)\n",
    "X_valid_pre = preprocessor.transform(X_valid)\n",
    "X_test_pre = preprocessor.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "05831446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in explicit_star_count that need to be filled\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='constant', fill_value = -1, missing_values=np.nan)\n",
    "X_train_pre_imputed = imputer.fit_transform(X_train_pre)\n",
    "X_valid_pre_imputed = imputer.transform(X_valid_pre)\n",
    "X_test_pre_imputed = imputer.transform(X_test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f9b2d",
   "metadata": {},
   "source": [
    "### Reporting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "267a66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to report the results of the predictions for future use\n",
    "def report(y_actual, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, y_pred)\n",
    "    macro_f1 = f1_score(y_actual, y_pred, average='macro')\n",
    "    \n",
    "    # Getting the roc auc score\n",
    "    lb = LabelBinarizer()\n",
    "    y_valid_bin = lb.fit_transform(y_actual)\n",
    "\n",
    "    # Binarize the predicted labels\n",
    "    y_pred_validlr_bin = lb.transform(y_pred)\n",
    "\n",
    "    # Calculate ROC AUC score\n",
    "    roc_auc = roc_auc_score(y_valid_bin, y_pred_validlr_bin, multi_class='ovr')\n",
    "    \n",
    "    # print metrics\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Macro F1 Score:\", macro_f1)\n",
    "    print(f'ROC AUC Score: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14ee70",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "876497ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;n_estimators&#x27;: [10, 50, 100]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'n_estimators': [10, 50, 100]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define hyperparameter grid for GridSearchCV\n",
    "param_gridrf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    # Add other hyperparameters to tune\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "gridrf = GridSearchCV(RandomForestClassifier(), param_grid=param_gridrf, cv=3, scoring='f1_macro')\n",
    "gridrf.fit(X_train_pre_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "9f4e6ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(gridrf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "0a81f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[826 176  62  52  32]\n",
      " [430 489 151 111  32]\n",
      " [147 212 556 216  47]\n",
      " [ 52  63 161 661 234]\n",
      " [ 41  41  52 203 791]]\n",
      "Accuracy: 0.5692017814319973\n",
      "Macro F1 Score: 0.5663577797846359\n",
      "ROC AUC Score: 0.7321741668079962\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 30)\n",
    "rf.fit(X_train_pre_imputed, y_train)\n",
    "\n",
    "# Predict and find results\n",
    "y_pred_validrf = rf.predict(X_valid_pre_imputed)\n",
    "\n",
    "report(y_valid, y_pred_validrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c53eb",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b3738e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "[CV 1/3] END .C=1, penalty=l1, solver=liblinear;, score=0.549 total time=   1.9s\n",
      "[CV 2/3] END .C=1, penalty=l1, solver=liblinear;, score=0.599 total time=   1.6s\n",
      "[CV 3/3] END .C=1, penalty=l1, solver=liblinear;, score=0.601 total time=   0.8s\n",
      "[CV 1/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=liblinear;, score=0.544 total time=   1.1s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=liblinear;, score=0.598 total time=   1.5s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=liblinear;, score=0.602 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.412 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.349 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.396 total time=   1.1s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.546 total time=   9.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.599 total time=  11.4s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.599 total time=  11.6s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=2, penalty=l1, solver=liblinear;, score=0.534 total time=   1.1s\n",
      "[CV 2/3] END .C=2, penalty=l1, solver=liblinear;, score=0.591 total time=   1.3s\n",
      "[CV 3/3] END .C=2, penalty=l1, solver=liblinear;, score=0.594 total time=   1.3s\n",
      "[CV 1/3] END .......C=2, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=2, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=2, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=2, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=2, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=2, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=2, penalty=l2, solver=liblinear;, score=0.540 total time=   1.6s\n",
      "[CV 2/3] END .C=2, penalty=l2, solver=liblinear;, score=0.593 total time=   2.1s\n",
      "[CV 3/3] END .C=2, penalty=l2, solver=liblinear;, score=0.594 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=2, penalty=l2, solver=lbfgs;, score=0.413 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=2, penalty=l2, solver=lbfgs;, score=0.393 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=2, penalty=l2, solver=lbfgs;, score=0.416 total time=   1.1s\n",
      "[CV 1/3] END .C=2, penalty=l2, solver=newton-cg;, score=0.537 total time=  10.3s\n",
      "[CV 2/3] END .C=2, penalty=l2, solver=newton-cg;, score=0.594 total time=  13.2s\n",
      "[CV 3/3] END .C=2, penalty=l2, solver=newton-cg;, score=0.593 total time=  13.3s\n",
      "[CV 1/3] END C=2, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=3, penalty=l1, solver=liblinear;, score=0.525 total time=   1.4s\n",
      "[CV 2/3] END .C=3, penalty=l1, solver=liblinear;, score=0.577 total time=   1.6s\n",
      "[CV 3/3] END .C=3, penalty=l1, solver=liblinear;, score=0.586 total time=   1.6s\n",
      "[CV 1/3] END .......C=3, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=3, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=3, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=3, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=3, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=3, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=3, penalty=l2, solver=liblinear;, score=0.535 total time=   1.7s\n",
      "[CV 2/3] END .C=3, penalty=l2, solver=liblinear;, score=0.589 total time=   2.2s\n",
      "[CV 3/3] END .C=3, penalty=l2, solver=liblinear;, score=0.586 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=3, penalty=l2, solver=lbfgs;, score=0.409 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=3, penalty=l2, solver=lbfgs;, score=0.385 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=3, penalty=l2, solver=lbfgs;, score=0.436 total time=   1.1s\n",
      "[CV 1/3] END .C=3, penalty=l2, solver=newton-cg;, score=0.529 total time=  11.3s\n",
      "[CV 2/3] END .C=3, penalty=l2, solver=newton-cg;, score=0.586 total time=  15.6s\n",
      "[CV 3/3] END .C=3, penalty=l2, solver=newton-cg;, score=0.587 total time=  16.1s\n",
      "[CV 1/3] END C=3, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=3, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=3, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=3, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=3, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=3, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=3, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=3, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=3, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=5, penalty=l1, solver=liblinear;, score=0.508 total time=   2.0s\n",
      "[CV 2/3] END .C=5, penalty=l1, solver=liblinear;, score=0.559 total time=   2.0s\n",
      "[CV 3/3] END .C=5, penalty=l1, solver=liblinear;, score=0.567 total time=   2.1s\n",
      "[CV 1/3] END .......C=5, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=5, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=5, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=5, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=5, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=5, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=5, penalty=l2, solver=liblinear;, score=0.528 total time=   1.7s\n",
      "[CV 2/3] END .C=5, penalty=l2, solver=liblinear;, score=0.579 total time=   2.3s\n",
      "[CV 3/3] END .C=5, penalty=l2, solver=liblinear;, score=0.579 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=5, penalty=l2, solver=lbfgs;, score=0.405 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=5, penalty=l2, solver=lbfgs;, score=0.368 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=5, penalty=l2, solver=lbfgs;, score=0.386 total time=   1.1s\n",
      "[CV 1/3] END .C=5, penalty=l2, solver=newton-cg;, score=0.525 total time=  14.1s\n",
      "[CV 2/3] END .C=5, penalty=l2, solver=newton-cg;, score=0.579 total time=  16.9s\n",
      "[CV 3/3] END .C=5, penalty=l2, solver=newton-cg;, score=0.578 total time=  16.9s\n",
      "[CV 1/3] END C=5, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l1, solver=liblinear;, score=0.490 total time=   2.4s\n",
      "[CV 2/3] END C=10, penalty=l1, solver=liblinear;, score=0.536 total time=   2.7s\n",
      "[CV 3/3] END C=10, penalty=l1, solver=liblinear;, score=0.541 total time=   2.8s\n",
      "[CV 1/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=liblinear;, score=0.519 total time=   2.1s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=liblinear;, score=0.568 total time=   2.7s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=liblinear;, score=0.568 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.406 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.396 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.383 total time=   1.1s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=newton-cg;, score=0.514 total time=  14.7s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=newton-cg;, score=0.565 total time=  24.8s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=newton-cg;, score=0.567 total time=  23.3s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "75 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.58310273        nan        nan 0.58146184 0.38578475 0.58136682\n",
      "        nan        nan        nan 0.57314104        nan        nan\n",
      " 0.57571237 0.40747672 0.57483851        nan        nan        nan\n",
      " 0.56264139        nan        nan 0.56988988 0.41004444 0.56734588\n",
      "        nan        nan        nan 0.54468252        nan        nan\n",
      " 0.56196359 0.38636102 0.56090267        nan        nan        nan\n",
      " 0.52206157        nan        nan 0.5514057  0.39498513 0.5486891\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 2, 3, 5, 10],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 2, 3, 5, 10],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 2, 3, 5, 10],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['liblinear', 'lbfgs', 'newton-cg']},\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_gridlr = {\n",
    "    'C': [1, 2, 3, 5, 10],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg']\n",
    "}\n",
    "\n",
    "gridlr = GridSearchCV(LogisticRegression(), param_grid=param_gridlr, cv = 3, scoring = 'f1_macro', verbose = 3)\n",
    "gridlr.fit(X_train_pre_imputed, pd.DataFrame(pd.read_csv(\"amazon_train.csv\"))['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "62858677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(gridlr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "bf8ec9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[806 227  51  33  31]\n",
      " [289 586 235  71  32]\n",
      " [ 87 219 636 199  37]\n",
      " [ 30  60 169 699 213]\n",
      " [ 24  37  49 201 817]]\n",
      "Accuracy: 0.6070572113737581\n",
      "Macro F1 Score: 0.6075758357909166\n",
      "ROC AUC Score: 0.7554613976591465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikhilpande/miniconda3/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "\n",
    "lr = LogisticRegression(C=1, penalty = 'l1', solver = 'liblinear', random_state = 0)\n",
    "ovo = OneVsOneClassifier(lr)\n",
    "ovo.fit(X_train_pre_imputed, y_train)\n",
    "\n",
    "y_pred_validlr = ovo.predict(X_valid_pre_imputed)\n",
    "\n",
    "report(y_valid, y_pred_validlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cef212",
   "metadata": {},
   "source": [
    "### Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "130194e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [1, 3],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [1, 3],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'learning_rate': [0.05, 0.1], 'max_depth': [1, 3],\n",
       "                         'n_estimators': [30, 50]},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting Classifier Grid Search\n",
    "GBparam_grid = {\n",
    "    'n_estimators': [30, 50],\n",
    "    'max_depth': [1, 3],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "    # Add other hyperparameters to tune\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "GBgrid = GridSearchCV(GradientBoostingClassifier(), param_grid=GBparam_grid, cv=3, scoring='f1_macro')\n",
    "GBgrid.fit(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "cc8b0d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "5b8fee5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[749 256  57  58  28]\n",
      " [306 565 209  94  39]\n",
      " [ 98 245 569 200  66]\n",
      " [ 48  89 165 619 250]\n",
      " [ 33  58  58 218 761]]\n",
      "Accuracy: 0.5589242891401165\n",
      "Macro F1 Score: 0.5596171553536291\n",
      "ROC AUC Score: 0.7252596091543485\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 3, n_estimators = 50)\n",
    "gb.fit(X_train_pre_imputed, y_train)\n",
    "\n",
    "y_pred_validgb = gb.predict(X_valid_pre_imputed)\n",
    "\n",
    "report(y_valid, y_pred_validgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acfa1dc",
   "metadata": {},
   "source": [
    "### Submit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "a708b23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>a4495</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>a4496</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>a4497</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>a4498</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>a4499</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  pred\n",
       "0        a0     1\n",
       "1        a1     1\n",
       "2        a2     1\n",
       "3        a3     1\n",
       "4        a4     2\n",
       "...     ...   ...\n",
       "4495  a4495     5\n",
       "4496  a4496     5\n",
       "4497  a4497     5\n",
       "4498  a4498     5\n",
       "4499  a4499     4\n",
       "\n",
       "[4500 rows x 2 columns]"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit\n",
    "\n",
    "submit_pred = ovo.predict(X_test_pre_imputed)\n",
    "\n",
    "submission_data = {'id':test_id, 'pred':submit_pred}\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "7d52fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('amazonmulti37.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
